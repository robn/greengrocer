#!/usr/bin/env perl

package greengrocer;

use 5.014;
use warnings;
use strict;

use Lucy;
use Path::Tiny;
use AnyEvent::Log;
use AnyEvent::Socket;
use AnyEvent::Handle;
use Date::Format qw(time2str);
use Date::Parse qw(str2time);
use Getopt::Std qw(getopts);
use Time::HiRes qw(gettimeofday tv_interval);

getopts('d:h', \my %OPTS);

my $INDEX_DIR = $OPTS{d};

my $ACTION = shift @ARGV;
my $handler = {
    agent    => \&agent,
    search   => \&search,
    optimize => \&optimize,
}->{$ACTION // ''};

say STDERR "E: unknown action: $ACTION" if $ACTION && !$handler;
usage() if !$INDEX_DIR || $OPTS{h} || !$ACTION || !$handler;

path($INDEX_DIR)->mkpath;

$handler->(@ARGV);

sub agent {
    local @ARGV = @_;
    getopts('l:p:i:', \my %opts);

    my $ip = $opts{l};
    my $port = $opts{p} // 5514;

    AnyEvent::Log::ctx->log_to_warn;
    AnyEvent::Log::ctx->fmt_cb(sub {
            sprintf "[greengrocer] %s %s\n", time2str("%Y-%m-%dT%H:%M:%S", time), $_[3];
    });
    my $log = AnyEvent::Log::logger("notice");

    my $cv = AnyEvent::condvar;

    my $interval = (0+($opts{i} // 0)) || 10;

    $log->("commit interval is $interval");

    my @queue;
    my $queue_guard; $queue_guard = AnyEvent->timer(
        after    => $interval,
        interval => $interval,
        cb => sub {
            return unless @queue;

            my %indexers;

            my ($t_start, $t_add, $t_commit);

            $t_start = [gettimeofday];

            for my $data (@queue) {
                @$data{qw(program pid)} = delete($data->{syslogtag}) =~ m/^([^\[]+)(?:\[(\d+)\])?:$/;
                $data->{pid} //= '';

                my ($y, $m, $d) = split '-', substr($data->{timestamp}, 0, 10);
                unless ($y && $m && $d) {
                    $log->("E: malformed timestamp: $data->{timestamp}");
                }
                my $key = "$y$m$d";

                ($indexers{$key} ||= Lucy::Index::Indexer->new(
                    index    => path($INDEX_DIR, $key),
                    schema => schema(),
                    create => 1,
                ))->add_doc($data);
            }

            $t_add = [gettimeofday];

            for my $indexer (values %indexers) {
                $indexer->commit;
            };

            $t_commit = [gettimeofday];

            my $e_add     = tv_interval($t_start, $t_add);
            my $e_commit  = tv_interval($t_add, $t_commit);

            my $n_items = scalar @queue;

            my $r_add    = $e_add / $n_items;
            my $r_commit = $e_commit / $n_items;

            $log->("indexed %d lines [add %.3f (%.6f) commit %.3f (%.6f)]", $n_items, $e_add, $r_add, $e_commit, $r_commit);

            undef @queue;
        },
    );

    tcp_server($ip, $port,
        sub {
            my ($fh, $host, $port) = @_;

            $log->("$host:$port connect");

            my $handle; $handle = AnyEvent::Handle->new(
                fh => $fh,
                on_error => sub {
                    my $msg = pop @_;
                    $handle->destroy;
                    $log->("$host:$port error: $msg");
                },
                on_eof => sub {
                    $handle->destroy;
                    $log->("$host:$port disconnect");
                },
            );

            my $reader; $reader = sub {
                push @queue, $_[-1];
                $handle->push_read(json => $reader);
            };
            $handle->push_read(json => $reader);
        },
        sub {
            my ($fh, $host, $port) = @_;
            $log->("$host:$port listening");
        },
    );

    $cv->recv;
}

sub search {
    local @ARGV = @_;
    getopts('s:e:j', \my %opts);

    my $now = time;
    my $start_date = time2str("%Y%m%d", str2time($opts{s}) // $now);
    my $end_date     = time2str("%Y%m%d", str2time($opts{e}) // ($now+86400));
    if ($start_date ge $end_date) {
        say STDERR "E: invalid date range $start_date - $end_date";
        usage();
    }

    my $query_parser = Lucy::Search::QueryParser->new(schema => schema());
    $query_parser->set_heed_colons(1);
    my $query = $query_parser->parse(join ' ', @ARGV);

    my $top_dir = path($INDEX_DIR);
    my @indexes = grep { my $basename = $_->basename; $basename >= $start_date && $basename < $end_date } $top_dir->children;
    my @searchers = map { Lucy::Search::IndexSearcher->new(index => $_) } @indexes;
    my $searcher = Lucy::Search::PolySearcher->new(
        schema => schema(),
        searchers => \@searchers,
    );

    my $collector = greengrocer::HitCollector->new(searcher => $searcher, json => !!$opts{j});

    do {
        no warnings 'uninitialized'; # working around slight bug inside Lucy
        $searcher->collect(
            query => $query,
            collector => $collector,
        );
    };
}

sub optimize {
    local @ARGV = @_;

    for my $index (@ARGV) {
        my $indexer = eval {
            Lucy::Index::Indexer->new(
                index  => path($INDEX_DIR, $index),
                schema => schema(),
            );
        };
        if ($@) {
            warn "E: couldn't open index $index, skipping\n";
            next;
        }

        print STDERR "indexing $index... ";
        STDERR->flush;

        $indexer->optimize;
        $indexer->commit;

        say STDERR "done";
    }
}

sub schema {
    # {"pid":"4090299","timestamp":"2015-12-21T18:47:30.697022-05:00","program":"sloti30t15/calalarmd","host":"imap30","message":" processing alarms"}

    state $schema = do {
        my $s = Lucy::Plan::Schema->new;

        $s->spec_field(
            name => 'timestamp',
            type => Lucy::Plan::StringType->new(
                sortable => 1,
            ),
        );
        $s->spec_field(
            name => 'host',
            type => Lucy::Plan::StringType->new,
        );
        $s->spec_field(
            name => 'program',
            type => Lucy::Plan::FullTextType->new(
                analyzer => Lucy::Analysis::StandardTokenizer->new,
            ),
        );
        $s->spec_field(
            name => 'pid',
            type => Lucy::Plan::StringType->new,
        );
        $s->spec_field(
            name => 'message',
            type => Lucy::Plan::FullTextType->new(
                analyzer => Lucy::Analysis::StandardTokenizer->new,
            ),
        );

        $s;
    };

    return $schema;
}

sub usage {
    my $action = $ACTION // '';

    if ($action eq 'agent') {
        print STDERR <<USAGE;
Usage: greengrocer -d <index-dir> agent [opts...]

Starts the log collection agent. The agent itself will log info about
its activities to standard error.

Options:
    -l <ip>       - IP address to listen on [default: all]
    -p <port>     - port to listen on [default: 5514]
    -i <interval> - commit logs to index every N seconds [default: 10]
USAGE
    }
    elsif ($action eq 'search') {
        print STDERR <<USAGE;
Usage: greengrocer -d <index-dir> search [opts...] <query...>

Searches for log lines matching the given query.

Options:
    -s <date> - start date to search (inclusive) [default: today]
    -e <date> - end date to search (exclusive) [default: tomorrow]
    -j        - JSON output
USAGE
    }
    elsif ($action eq 'optimize') {
        print STDERR <<USAGE;
Usage: greengrocer -d <index-dir> optimize <indexes...>

Optimizes a indexes for fast searching. Indexes can become fragmented after a
lot of writes, which can make searching slower. Optimizing reprocesses the log
lines into a new unfragmented index which takes less effort to search. It
usually won't make the index significantly smaller.

Optimizing an index can take a long time (minutes) and locks the index for
writing, so new log entries cannot be added. For this reason don't try to
optimize an active index (that is, today's) or you'll likely end up losing
incoming log lines.
USAGE
    }
    else {
        print STDERR <<USAGE;
Usage: greengrocer -d <index-dir> <action> [opts...]

Global options:
    -d <index-dir> - location to store indexes

Actions:
    agent    - run the log collection agent
    search   - show log lines matching a query
    optimize - optimize indexes for searching

For more help on action: greengrocer <action> -h
USAGE
    }

    exit 1;
}


package greengrocer::HitCollector;

use parent qw(Lucy::Search::Collector);
use JSON::XS;

our %self;

sub new {
    my ($class, %args) = @_;

    my $ref = $class->SUPER::new;

    $self{$ref} = {
        searcher => $args{searcher},
        base     => 0,
        json     => $args{json},
    };

    return $ref;
}

sub DESTROY {
    my ($ref) = @_;
    my $self = delete $self{$ref};
    if ($self->{json}) {
        if ($self->{started}) {
            say "\n]";
        }
        else {
            say "[]";
        }
    }
}

sub _output_text {
    my ($self, $doc) = @_;
    my ($timestamp, $host, $program, $pid, $message) = map { $doc->{$_} } qw(timestamp host program pid message);
    $pid = "[$pid]" if $pid;
    printf "%s %s %s%s:%s\n", $timestamp, $host, $program, $pid, $message;
}

sub _output_json {
    my ($self, $doc) = @_;

    unless ($self->{started}) {
        say '[';
        $self->{started} = 1;
    }
    else {
        say ',';
    }

    print '  ', encode_json({ map { $_ => $doc->{$_} } qw(timestamp host program pid message) });
}

sub collect {
    my ($ref, $doc_id) = @_;
    my $self = $self{$ref};
    my $doc = $self->{searcher}->fetch_doc($self->{base} + $doc_id);
    if ($self->{json}) {
        _output_json($self, $doc);
    }
    else {
        _output_text($self, $doc);
    }
}

sub set_base {
    my ($ref, $base) = @_;
    my $self = $self{$ref};
    $self->{base} = $base;
}

sub need_score { 0 }
